{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ecf9005-fc63-439f-92d7-81c19083a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "385a8085-9111-4b11-aec6-8c054ad280b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "MODEL_BACKEND = os.getenv(\"MODEL_BACKEND\", \"ollama\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"llama3.2\")\n",
    "OLLAMA_API_BASE = os.getenv(\"OLLAMA_API_BASE\", \"http://localhost:11434\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d676ed80-da61-4643-88dc-d1570a8ca7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confiig\n",
    "INPUT_FILE = \"ML-data.txt\"\n",
    "OUTPUT_FILE = \"ML-data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6227a2fe-84aa-4ef0-a5a6-402f53214f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURE OPENAI ===\n",
    "if MODEL_BACKEND == \"openai\":\n",
    "    openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a95e2ca-6b90-49c4-8a44-e94585bf8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === READ RAW PROJECTS ===\n",
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = f.read()\n",
    "\n",
    "project_blocks = re.split(r'\\n?\\s*\\d+\\.\\s+', raw_data.strip())\n",
    "project_blocks = [p.strip() for p in project_blocks if p.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "462a5e0a-0822-4c23-8ef6-63d8c3c204c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_ollama(title, description):\n",
    "    system_prompt = (\n",
    "        \"You are a dataset formatter AI. You must return only valid JSON with two keys: \"\n",
    "        \"'tech_stack' and 'objective'. No markdown, no commentary, no extra text.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "### Example JSON Format\n",
    "{{\n",
    "  \"tech_stack\": \"Python, Flask, TensorFlow, HTML, CSS\",\n",
    "  \"objective\": \"To develop a web-based ML platform that predicts or automates a specific domain problem.\"\n",
    "}}\n",
    "\n",
    "### Project Details\n",
    "Title: {title}\n",
    "Description: {description}\n",
    "\n",
    "Now output valid JSON in the same format as the example above.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OLLAMA_API_BASE}/api/generate\",\n",
    "            json={\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"prompt\": f\"{system_prompt}\\n{user_prompt}\",\n",
    "                \"stream\": False,\n",
    "                \"options\": {\"temperature\": 0.2}  # More deterministic\n",
    "            },\n",
    "            timeout=60\n",
    "        )\n",
    "        data = response.json()\n",
    "        output = data.get(\"response\", \"\").strip()\n",
    "\n",
    "        # --- Cleanup ---\n",
    "        cleaned = (\n",
    "            output.replace(\"```json\", \"\")\n",
    "            .replace(\"```\", \"\")\n",
    "            .strip()\n",
    "        )\n",
    "        start, end = cleaned.find(\"{\"), cleaned.rfind(\"}\") + 1\n",
    "        json_str = cleaned[start:end]\n",
    "        return json.loads(json_str)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Ollama parse error for {title}: {e}\")\n",
    "        return {\n",
    "            \"tech_stack\": \"Python, Flask (fallback)\",\n",
    "            \"objective\": \"Automatic generation failed; placeholder added.\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bf99127-6ee4-486c-b079-0fca58ed0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tech_stack(tech_stack):\n",
    "    \"\"\"\n",
    "    Converts tech_stack (dict, list, or string) into a clean comma-separated string.\n",
    "    Handles LLM outputs like {\"front-end\": [...]} or [\"Python\", \"Flask\"].\n",
    "    \"\"\"\n",
    "    if isinstance(tech_stack, dict):\n",
    "        # Merge all list values into one list\n",
    "        all_items = []\n",
    "        for v in tech_stack.values():\n",
    "            if isinstance(v, list):\n",
    "                all_items.extend(v)\n",
    "            else:\n",
    "                all_items.append(str(v))\n",
    "        return \", \".join(all_items)\n",
    "    elif isinstance(tech_stack, list):\n",
    "        return \", \".join(map(str, tech_stack))\n",
    "    else:\n",
    "        return str(tech_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e6ae14e-183d-43fd-af51-7b8af260c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Raw Output for Instagram Reach Analysis ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"tech_stack\": {\n",
      "        \"languages\": [\"Python\"],\n",
      "        \"libraries\": [\n",
      "            \"Pandas\",\n",
      "            \"NumPy\",\n",
      "            \"Matplotlib\",\n",
      "            \"Seaborn\",\n",
      "            \"Plotly\"\n",
      "        ],\n",
      "        \"frameworks\": null\n",
      "    },\n",
      "    \"objective\": \"Analyze Instagram reach data to identify factors influencing post visibility using Python libraries.\"\n",
      "}\n",
      "```\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Instagram Reach Analysis\n",
      "\n",
      "---- Raw Output for Scraping laptop data from Amazon ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "{\"tech_stack\": \"Python 3.9, BeautifulSoup4, requests, pandas, NumPy\", \"objective\": \"Scrape laptop data from Amazon to aid in price comparison and market research.\"}\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Scraping laptop data from Amazon\n",
      "\n",
      "---- Raw Output for Video Game Sales Prediction ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"tech_stack\": {\n",
      "    \"programming_language\": \"Python\",\n",
      "    \"libraries\": [\n",
      "      \"Pandas\",\n",
      "      \"NumPy\",\n",
      "      \"Matplotlib\",\n",
      "      \"Seaborn\",\n",
      "      \"Plotly\",\n",
      "      \"Scikit-learn\",\n",
      "      \"TensorFlow\"\n",
      "    ],\n",
      "    \"frameworks\": [],\n",
      "    \"database\": null\n",
      "  },\n",
      "  \"objective\": \"Build a machine learning model to predict video game sales based on various game attributes using regression algorithms.\"\n",
      "}\n",
      "```\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Video Game Sales Prediction\n",
      "\n",
      "---- Raw Output for Heart disease detection ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"tech_stack\": {\n",
      "    \"language\": [\"Python\"],\n",
      "    \"frameworks\": [\"Scikit-learn\", \"TensorFlow\"],\n",
      "    \"libraries\": [\"Pandas\", \"NumPy\", \"Matplotlib\", \"Seaborn\", \"Plotly\"]\n",
      "  },\n",
      "  \"objective\": [\n",
      "    \"Build a machine learning model that detects the presence of heart disease with high accuracy.\",\n",
      "    \"Utilize supervised learning techniques to analyze medical data and provide early detection tools for patients and doctors alike.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Heart disease detection\n",
      "\n",
      "---- Raw Output for Food order prediction ----\n",
      "Here is the output:\n",
      "\n",
      "{\"tech_stack\": {\"framework\": \"Python\", \"library\": [\"Pandas\", \"NumPy\", \"Scikit-learn\", \"TensorFlow\"], \"language\": \"Python\"}, \"objective\": \"Predict customer food orders based on preferences and location to inform inventory management, marketing campaigns, and supply chain optimization.\"}\n",
      "\n",
      "Let me know if you need anything else.\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Food order prediction\n",
      "\n",
      "---- Raw Output for Contact tracing system ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"tech_stack\": {\n",
      "    \"frameworks\": [\"Python\", \"Flask\"],\n",
      "    \"libraries\": [\"NumPy\", \"Pandas\", \"Scikit-learn\", \"Matplotlib\", \"Seaborn\"],\n",
      "    \"languages\": [\"Python\"]\n",
      "  },\n",
      "  \"objective\": [\n",
      "    \"Develop a contact tracing system using machine learning algorithms to predict whether an individual was in close contact with an infected person.\",\n",
      "    \"Integrate the system with public health institutions to track and monitor individuals who might be exposed to a contagious disease.\",\n",
      "    \"Evaluate the model's performance using different evaluation metrics like MSE, R-squared, and MAE.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Contact tracing system\n",
      "\n",
      "---- Raw Output for Sarcasm detection ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"tech_stack\": {\n",
      "    \"language\": \"Python\",\n",
      "    \"libraries\": [\"BeautifulSoup\", \"requests\", \"scikit-learn\", \"numpy\", \"pandas\"],\n",
      "    \"frameworks\": [\"TensorFlow\"]\n",
      "  },\n",
      "  \"objective\": \"Train a machine learning model to detect sarcasm in text using supervised learning algorithms and evaluate its performance with various metrics.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Please note that the tech stack is not exhaustive, but it includes some of the most relevant libraries and frameworks for this project. Also, TensorFlow could be replaced by other machine learning frameworks like Keras or PyTorch if preferred.\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Sarcasm detection\n",
      "\n",
      "---- Raw Output for Medical insurance price prediction ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"tech_stack\": {\n",
      "    \"framework\": \"Python\",\n",
      "    \"libraries\": [\"Scikit-learn\", \"Pandas\", \"NumPy\", \"Matplotlib\", \"Seaborn\"],\n",
      "    \"web_scraper\": \"BeautifulSoup\"\n",
      "  },\n",
      "  \"objective\": [\n",
      "    \"Build a machine learning model to predict medical insurance prices based on various factors.\",\n",
      "    \"Optimize the model for better performance using ensemble techniques like bagging and boosting.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "This JSON object includes the project's tech stack (Python, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn) and a concise description of the project objective.\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Medical insurance price prediction\n",
      "\n",
      "---- Raw Output for Credit card clustering ----\n",
      "Here is the source code for the Credit Card Clustering Project:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"tech_stack\": {\n",
      "        \"frameworks\": [\"Python\", \"Flask\"],\n",
      "        \"libraries\": [\n",
      "            \"Pandas\",\n",
      "            \"NumPy\",\n",
      "            \"Matplotlib\",\n",
      "            \"Seaborn\",\n",
      "            \"Plotly\",\n",
      "            \"Scikit-learn\",\n",
      "            \"Scipy\"\n",
      "        ],\n",
      "        \"languages\": [\"SQL\"]\n",
      "    },\n",
      "    \"objective\": \"Build a clustering model to identify customer segments based on their credit card spending patterns.\"\n",
      "}\n",
      "```\n",
      "\n",
      "This tech stack includes Python as the primary language, with Flask as the web framework. The libraries used are Pandas and NumPy for data manipulation and analysis, Matplotlib, Seaborn, and Plotly for data visualization, Scikit-learn and SciPy for machine learning tasks, and SQL for database operations.\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Credit card clustering\n",
      "\n",
      "---- Raw Output for MNIST Data ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "{\n",
      "  \"tech_stack\": [\n",
      "    \"Python\",\n",
      "    \"NumPy\",\n",
      "    \"Scikit-learn\",\n",
      "    \"Pandas\",\n",
      "    \"Matplotlib\",\n",
      "    \"Seaborn\",\n",
      "    \"Plotly\"\n",
      "  ],\n",
      "  \"objective\": \"Build a machine learning project using MNIST dataset to recognize handwritten digits and evaluate its performance\"\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: MNIST Data\n",
      "\n",
      "---- Raw Output for Real time sentiment analysis ----\n",
      "Here is the JSON output:\n",
      "\n",
      "{\"tech_stack\": [\"Python 3.x\", \"Flask\", \"Scikit-learn\", \"Pandas\", \"Matplotlib\", \"NumPy\"], \"objective\": \"Build a real-time sentiment analysis system that determines emotional tone behind text and classifies sentiment as positive, negative, or neutral using machine learning algorithms.\"}\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Real time sentiment analysis\n",
      "\n",
      "---- Raw Output for News recommendation system ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"tech_stack\": {\n",
      "    \"frameworks\": [\"Flask\"],\n",
      "    \"libraries\": [\"BeautifulSoup\", \"Pandas\", \"NumPy\", \"Scikit-learn\", \"TensorFlow\"],\n",
      "    \"languages\": [\"Python\"]\n",
      "  },\n",
      "  \"objective\": [\n",
      "    \"Develop a personalized news recommendation system using web scraping, content-based filtering, and collaborative filtering\",\n",
      "    \"Train a machine learning model to recommend news articles to individual users based on their preferences\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: News recommendation system\n",
      "\n",
      "---- Raw Output for Calories Burnt Prediction ----\n",
      "Here is the JSON output:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"tech_stack\": {\n",
      "        \"programming_language\": \"Python\",\n",
      "        \"web_framework\": \"Flask\",\n",
      "        \"machine_learning_library\": \"Scikit-Learn\",\n",
      "        \"data_preprocessing_library\": \"Pandas\"\n",
      "    },\n",
      "    \"objective\": [\n",
      "        \"Develop a machine learning model to predict calories burnt based on various factors\",\n",
      "        \"Integrate the model with a web application for user input and prediction\",\n",
      "        \"Provide accurate calorie burn estimates for fitness companies, individuals, athletes, and coaches\"\n",
      "    ]\n",
      "}\n",
      "```\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Calories Burnt Prediction\n",
      "\n",
      "---- Raw Output for Online Payment Fraud Detection ----\n",
      "Here is the output in JSON format:\n",
      "\n",
      "{\"tech_stack\": \"Python 3.8+, Pandas, NumPy, matplotlib, Scikit-learn, Flask\", \"objective\": \"Build a machine learning model to detect online payment fraud using data preprocessing and feature engineering techniques.\"}\n",
      "-----------------------------\n",
      "\n",
      "✅ Processed: Online Payment Fraud Detection\n",
      "\n",
      "---- Raw Output for Rainfall Prediction system ----\n",
      "Here is the JSON output:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"tech_stack\": {\n",
      "    \"languages\": [\"Python\"],\n",
      "    \"frameworks\": [\"Flask\" or \"Django\" for web application],\n",
      "    \"libraries\": [\"Scikit-learn\", \"Pandas\", \"NumPy\", \"Matplotlib\", \"Seaborn\" for data preprocessing and visualization],\n",
      "    \"websites\": [\"Kaggle\" or \"UCI Machine Learning Repository\" for collecting meteorological data]\n",
      "  },\n",
      "  \"objective\": [\n",
      "    \"Predict rainfall patterns using machine learning algorithms\",\n",
      "    \"Develop a web application to provide early warnings for disaster management authorities\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "-----------------------------\n",
      "\n",
      "⚠️ JSON parse failed for Rainfall Prediction system: Expecting ',' delimiter: line 4 column 28 (char 76)\n",
      "✅ Processed: Rainfall Prediction system\n"
     ]
    }
   ],
   "source": [
    "# === MAIN PROCESSING LOOP ===\n",
    "structured_projects = []\n",
    "\n",
    "for idx, block in enumerate(project_blocks, start=1):  # process all projects\n",
    "    lines = block.split('\\n', 1)\n",
    "    title = lines[0].strip()\n",
    "    description = lines[1].strip() if len(lines) > 1 else \"\"\n",
    "\n",
    "    # Domain guess\n",
    "    desc_lower = description.lower()\n",
    "    if any(x in desc_lower for x in [\"ai\", \"machine learning\", \"deep learning\", \"data\"]):\n",
    "        domain = \"Artificial Intelligence / Data Science\"\n",
    "    elif any(x in desc_lower for x in [\"iot\", \"sensor\", \"arduino\", \"raspberry\"]):\n",
    "        domain = \"IoT / Embedded Systems\"\n",
    "    elif any(x in desc_lower for x in [\"app\", \"mobile\", \"fitness\", \"health\"]):\n",
    "        domain = \"Mobile / HealthTech\"\n",
    "    elif any(x in desc_lower for x in [\"web\", \"ecommerce\", \"dashboard\"]):\n",
    "        domain = \"Web / Software Engineering\"\n",
    "    else:\n",
    "        domain = \"General Computing\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a dataset preparation assistant. Given this project:\n",
    "\n",
    "Title: {title}\n",
    "Description: {description}\n",
    "\n",
    "Generate:\n",
    "1. A realistic tech stack (frameworks, libraries, languages)\n",
    "2. A concise 2-3 line project objective\n",
    "\n",
    "Output strictly in JSON with keys: tech_stack, objective\n",
    "\"\"\"\n",
    "\n",
    "    ai_output = call_llm(prompt)\n",
    "\n",
    "    # Debug log\n",
    "    print(f\"\\n---- Raw Output for {title} ----\\n{ai_output}\\n-----------------------------\\n\")\n",
    "\n",
    "    # Clean & parse JSON\n",
    "    try:\n",
    "        cleaned_output = (\n",
    "            ai_output.strip()\n",
    "            .replace(\"```json\", \"\")\n",
    "            .replace(\"```\", \"\")\n",
    "            .strip()\n",
    "        )\n",
    "        start = cleaned_output.find(\"{\")\n",
    "        end = cleaned_output.rfind(\"}\") + 1\n",
    "        json_str = cleaned_output[start:end]\n",
    "        parsed = json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ JSON parse failed for {title}: {e}\")\n",
    "        parsed = {\n",
    "            \"tech_stack\": \"Python, Flask (fallback)\",\n",
    "            \"objective\": \"Automatic generation failed; placeholder added.\"\n",
    "        }\n",
    "\n",
    "    year = str(random.randint(2020, 2024))\n",
    "\n",
    "    structured_projects.append({\n",
    "        \"project_id\": f\"auto{idx:03}\",\n",
    "        \"title\": title,\n",
    "        \"description\": description,\n",
    "        \"domain\": domain,\n",
    "        \"year\": year,\n",
    "        \"tech_stack\": flatten_tech_stack(parsed.get(\"tech_stack\", \"Python, Flask (fallback)\")),\n",
    "        \"objective\": parsed.get(\"objective\", \"Automatic generation failed; placeholder added.\"),\n",
    "        \"source\": \"ISE-dept\"\n",
    "    })\n",
    "\n",
    "\n",
    "    print(f\"✅ Processed: {title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fcde4703-c8c2-46d7-9634-f604c233b565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done! 15 projects saved → ML-data.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === SAVE FINAL JSON ===\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(structured_projects, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Done! {len(structured_projects)} projects saved → {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9de8b-d390-4fef-b084-53ee17cdeb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

[
  {
    "project_id": "auto001",
    "title": "Instagram Reach Analysis",
    "description": "Instagram reach analysis is a vital topic for social media marketing. This project aims at teaching learners how to use data to analyze their Instagram reach. It involves collecting data on the reach of your past posts and using Python to understand how different factors affect the number of people who see your posts.\n\nLearning outcomes: \n\n    Understanding of Machine Learning concepts: Have a solid grasp of the fundamentals of machine learning, its workflow, and common data preprocessing techniques \n    Data Exploration:  Use of Python libraries like Pandas and NumPy for data manipulation and analysis\n    Data Visualization: Knowledge of Python in-built tools like Matplotlib, Seaborn, and Plotly for creating charts and tables and improved data analysis \n\nHow to build this machine learning project:\n\n    Manually gather â€˜reachâ€™ data from Instagram insights about past posts\n    Import them from CSV file into Python using libraries like Pandas, and clean and organize the data for analysis \n    Use Python libraries like Matplotlib, Seaborn, and Plotly to calculate different metrics, create data visualization, and identify patterns \n    Depending on your data analysis, draw conclusions on which factors influence your Instagram reach \n\nReal world applications: \n\n    Marketers can use this tool to identify what attracts consumers\n    Businesses can use them to see how people welcome their products\n    Content creators use it to understand which kind of post goes viral and attract followers \n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2023",
    "tech_stack": "Python, Pandas, NumPy, Matplotlib, Seaborn, Plotly, None",
    "objective": "Analyze Instagram reach data to identify factors influencing post visibility using Python libraries.",
    "source": "ISE-dept"
  },
  {
    "project_id": "auto002",
    "title": "Scraping laptop data from Amazon",
    "description": "This project aims to use Python libraries to scrape and extract data on laptop models, features, and pricing from Amazon. You will learn how to automate the process of collecting product data from Amazon which will help you in price comparison, market research, and data-driven decision making. \n\nLearning outcomes: \n\n    Basic knowledge of Machine Learning: Get hands-on training on the working of machine learning techniques \n    Web scraping: Learn using Python libraries like BeautifulSoup or requests to parse and extract data from HTML web pages and handle different types of data on websites, including tables and forms\n    URL handling: Understand how to construct and manipulate URLs to navigate through different product pages on Amazon\n    Data cleaning and transformation: Practice cleaning and organizing scraped data into a structured format such as CSV and JSON files or databases\n    Data preprocessing and storage: Knowledge of saving the cleaned data to a local file or a cloud storage \n\nHow to build this machine learning project:\n\n    Set up the development environment by installing Python and its necessary libraries\n    Identify the target Amazon laptop product URL that you want to scrape \n    Develop the scraping code using Python, extract the required data, and store it in a structured format like a CSV file\n    Run your code and resolve any bugs within it, like issues with handling dynamic content or working with website changes\n\nReal world applications: \n\n    Website scraping helps businesses monitor product prices and other features of their competitors \n    Helps market researchers to collect data on multiple topics for developing a case study or research work\n    Assists marketers in understanding customer preferences and upcoming trends for making strategic decisions \n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2024",
    "tech_stack": "Python 3.9, BeautifulSoup4, requests, pandas, NumPy",
    "objective": "Scrape laptop data from Amazon to aid in price comparison and market research.",
    "source": "ISE-dept"
  },
  {
    "project_id": "auto003",
    "title": "Video Game Sales Prediction",
    "description": "This Video Game Sales Prediction project aims at using a supervised data learning technique, regression. Learners will work with previous data of video game sales and build a model that can predict future trends and sales depending on various game attributes like genre, platform, etc. \n\nLearning outcomes: \n\n    Basic Machine Learning knowledge: Learn the basic concepts of machine learning and know how it works in the real world \n    Data manipulation: Knowledge of data manipulation and analysis techniques using Python libraries Pandas and NumPy to summarize, filter, and transform video game sales data\n    EDA (Exploratory Data Analysis): Practice analyzing and visualizing data using Python libraries like Matplotlib, Seaborn, and Plotly \n    Data engineering and pre-processing: Learn how to select and transform relevant data features to improve the prediction performance of your regression model\n    Web scraping: Implement knowledge of web scraping to collect video game sales data from multiple web pages\n    Supervisor learning-Regression: Learn the use of regression algorithms like linear regression, polynomial regression, and Lasso and Ridge regression\n    Regression model evaluation: Understanding of how to use different evaluation metrics for the regression model, including Mean Squared Error (MSE), R-squared, and Mean Absolute Error (MAE) to measure the model performance \n    Model deployment: Learn how to deploy trained models to make sales predictions on new and unseen video game data\n\nHow to build this machine learning project:\n\n    Set up the development environment by installing Python and its libraries like Pandas, NumPy, Matplotlib, Seaborn, and Plotly \n    Use web scraping to obtain video game sales data \n    Implementation of data engineering methods to clean the data, handle missing values, use feature engineering techniques for creating new features, handle data and time variables, and encode categorical variables \n    Split the data into two parts, one for training and the other for testing \n    Train the regression model with a suitable algorithm like linear regression, polynomial regression, or Lasso and Ridge regression \n    Assess the performance of the regression model using different evaluation metrics \n    Optimize the model using different feature engineering techniques and model to improve the prediction performance of the model \n    Use the trained model to make predictions of future video game sales\n\nReal world applications: \n\n    Video game companies can use the model to predict their sales for new game releases and think about their production, marketing, and pricing \n    Marketers can use it to forecast future sales and make informed decisions about their marketing campaigns \n    Video game publishers can use it to identify which game they should invest in and which one to stop for increased revenue and profitability \n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2022",
    "tech_stack": "Python, Pandas, NumPy, Matplotlib, Seaborn, Plotly, Scikit-learn, TensorFlow, None",
    "objective": "Build a machine learning model to predict video game sales based on various game attributes using regression algorithms.",
    "source": "ISE-dept"
  },
  {
    "project_id": "auto004",
    "title": "Heart disease detection",
    "description": "The heart disease detection project aims to build a tool that will help users detect the presence of heart disease. It uses Python and the supervised learning technique of classification to accurately predict the presence of a heart disease based on different medical factors.\n\nLearning outcomes: \n\n    Knowledge of machine learning basics: Understanding how the entire machine learning process works\n    Data manipulation and analysis: Learn the use of Python libraries Pandas and NumPy for data manipulation and analysis, data cleaning, handling missing values, and dealing with outliers \n    Data visualization: Use of Python libraries like Matplotlib, Seaborn, and Plotly for data visualization \n    Data preprocessing: Understanding of data clearing and handling missing values, feature engineering techniques, data scaling and normalization, and dealing with categorical variables \n    Supervised learning model selection and evaluation: Use of appropriate supervised learning algorithms like logistic regression, decision trees, and random forests \n    Evaluating model performance: Knowledge of different model performance evaluation metrics\n\nHow to build this machine learning project:\n\n    Download and install Python and its necessary libraries on your system \n    Obtain the required data from websites using web scraping \n    Preprocessing of data by cleaning data, handling missing values, and encoding categorical variables \n    Perform EDA (Exploratory Data Analysis) to understand the relationship between different features and target variables to identify the presence of a heart disease \n    Split the data into two parts, one for training the model and the other for testing the modelâ€™s performance \n    Select an appropriate supervised learning algorithm, train it with the data, and optimize its performance \n    Evaluate the performance of the model using the testing data; if itâ€™s not up to the mark, use different feature engineering techniques to improve results \n\nReal world applications: \n\n    Doctors can use the tool to detect any hidden heart diseases in a patient during emergencies \n    Patients can use it for personal use to detect any heart disease early and take immediate actions\n    Hospitals can integrate the tool with their clinical decision support system to help doctors and nurses quickly assess patientâ€™s risk of heart disease based on their medical data\n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2024",
    "tech_stack": "Python, Scikit-learn, TensorFlow, Pandas, NumPy, Matplotlib, Seaborn, Plotly",
    "objective": [
      "Build a machine learning model that detects the presence of heart disease with high accuracy.",
      "Utilize supervised learning techniques to analyze medical data and provide early detection tools for patients and doctors alike."
    ],
    "source": "ISE-dept"
  },
  {
    "project_id": "auto005",
    "title": "Food order prediction",
    "description": "This food order prediction project aims to predict customersâ€™ food orders based on their preferences, location, past orders, time of the day, etc. Learners will build a classification model using supervised learning techniques and Python libraries to make predictions. \n\nLearning outcomes: \n\n    Understanding of Machine Learning work process: Get to know how machine learning works in the real world \n    Data processing: Learn to clean, transform, and prepare data for training, along with handling missing values and encoding categorical variables \n    Exploratory Data Analysis (EDA): Understand data visualization, learn the relationships between features, and gain insights on how to select the appropriate machine learning algorithm \n    Model selection: Experiment with multiple supervised learning algorithms, evaluating their performance and optimizing their accuracy \n    Model evaluation: Knowledge of assessing the performance of the classification model using multiple evaluation metrics \n\nHow to build this machine learning project:\n\n    Collect the required dataset containing customer food order information like types of food ordered, time of order, location, etc \n    Use Python libraries like Pandas and NumPy to prepare your data, identify patterns, and clean inconsistencies\n    Split the data into parts, one for training and the other for testing \n    Train your model on the training data, allowing it to learn different patterns that influence customersâ€™ food choices\n    Test the model to check for its performance and accuracy \n\nReal world applications: \n\n    Restaurants can use it to forecast customer orders and keep their stock filled, have proper staff, and be ready for the food preparation process\n    Food delivery apps can use this to provide personalized food recommendations to customers based on their search or past orders\n    Food producers and distributors can use the model to predict food habit changes or demands and plan for better production and distribution strategy \n    Marketers can use it to develop targeted marketing campaigns, offering personalized promotions based on customer preferences \n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2024",
    "tech_stack": "Python, Pandas, NumPy, Scikit-learn, TensorFlow, Python",
    "objective": "Predict customer food orders based on preferences and location to inform inventory management, marketing campaigns, and supply chain optimization.",
    "source": "ISE-dept"
  },
  {
    "project_id": "auto006",
    "title": "Contact tracing system",
    "description": "This project aims at tracing whether an individual was in contact with an infected person. The contact tracing system can predict whether an individual has been in close contact with an infected person based on various factors. It will assist public health institutions in managing the spread of infectious disease\n\nLearning outcomes: \n\n    Understanding of Machine Learning concepts: Knowledge of how machine learning techniques work in the real world \n    Data preprocessing: Learning how to clean, format, and handle missing values in a dataset \n    Exploratory Data Analysis EDA: Analyzing data to understand relationships between features and target variable\n    Supervised Machine Learning algorithms: Implementing and comparing the performance of Supervised Machine Learning algorithms like SVM (Support Vector Machine), K-Nearest Neighbors (KNN), and Naive Bayes\n    Use of evaluation metrics: Checking the accuracy of the trained machine using different evaluation metrics like MSE (Mean Squared Error), R-squared, and MAE (Mean Absolute Error)\n\nHow to build this machine learning project:\n\n    Set up the development environment by installing Python and its libraries \n    Generate the required data like location, time, duration of encounters, and personal details of individuals \n    Preprocess the data by cleaning and handling missing values, encoding categorical variables, and feature scaling \n    Split data into two parts: training and testing datasets and use of algorithms like SVM, KNN, and Naive Bayes to train the model\n    Evaluate the modelâ€™s performance with different evaluation metrics \n    Use the system to make predictions on new contact tracing data\n\nReal world applications: \n\n    Public health authorities can use the system to quickly identify and monitor individuals who might be exposed to a contiguous disease and prevent the spread of the outbreak\n    During a pandemic, this system can be integrated with a larger healthcare system to track the movement of an infected individual and their contacts\n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2024",
    "tech_stack": "Python, Flask, NumPy, Pandas, Scikit-learn, Matplotlib, Seaborn, Python",
    "objective": [
      "Develop a contact tracing system using machine learning algorithms to predict whether an individual was in close contact with an infected person.",
      "Integrate the system with public health institutions to track and monitor individuals who might be exposed to a contagious disease.",
      "Evaluate the model's performance using different evaluation metrics like MSE, R-squared, and MAE."
    ],
    "source": "ISE-dept"
  },
  {
    "project_id": "auto007",
    "title": "Sarcasm detection",
    "description": "This circles and detection project aims to help learners understand the use of natural language processing and supervised learning algorithms. This model will accurately identify sarcastic statements in the text. For that, you need to train a machine learning model to classify between sarcastic and non sarcastic statements.\n\nLearning outcomes: \n\n    Knowledge of Python programming: Learn the use of different Python libraries and codes to implement Machine Learning projects \n    Text data preprocessing: Understanding of how to preprocess and clean text data \n    Feature engineering techniques: Use of different feature engineering techniques to create new features from text data, sentiment analysis, and encoding categorical variables\n    Supervised learning algorithms: Implement different supervised learning algorithms \n    Use of evaluation metrics: Verify the performance of a machine learning model using different evaluation metrics \n\nHow to build this machine learning project:\n\n    Collect data of sarcastic and non sarcastic statements using web scraping techniques and Python libraries like BeautifulSoup or requests \n    Clean and preprocess the data and handle missing values for training the model\n    Perform feature engineering techniques to extract features from the preprocessed data and use appropriate Machine Learning algorithms to train the model to distinguish between sarcastic and non sarcastic statements \n    Split the dataset into training and testing sets and train the model using supervised learning algorithms like SVM, KNN, and Naive Bayes \n    Evaluate the performance of the model with appropriate metrics and optimize the system for better outcomes \n    Integrate the system into larger applications or systems to detect sarcasm in real-time text inputs\n\nReal world applications: \n\n    Companies can implement this system to analyze customer sentiment on their product line and understand customer complaints expressed in a sarcastic way\n    Customer care service providers can use this tool to recognize the tone and intent of customer communication and offer them personalized and empathetic responses\n    Online platforms and communities can use this sarcasm detection system to identify and filter out harmful or inappropriate content and promote a positive environment \n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2022",
    "tech_stack": "Python, BeautifulSoup, requests, scikit-learn, numpy, pandas, TensorFlow",
    "objective": "Train a machine learning model to detect sarcasm in text using supervised learning algorithms and evaluate its performance with various metrics.",
    "source": "ISE-dept"
  },
  {
    "project_id": "auto008",
    "title": "Medical insurance price prediction",
    "description": "This project aims to build a model that can predict medical insurance prices based on certain factors like age, body mass index, sex, number of children, etc. It will help families to identify their insurance premiums and get themselves covered for emergency health scenarios.\n\nLearning outcomes: \n\n    Basic knowledge of Machine Learning and Python coding: Learn how Machine Learning works and how to implement Python libraries in ML projects\n    Data preprocessing: Understanding how to import and clean datasets, handle missing values, and encode categorical variables \n    Exploratory Data Analysis EDA: Knowledge of analyzing datasets using Python libraries to find out relationships between the features and target variable \n    Model selection: Understanding different supervised learning algorithms like linear regression, decision trees, random forests, etc., and choosing the appropriate one\n    Model performance evaluation: Use different evaluation metrics to check the model performance and optimize it for better results \n    Ensemble Methods and Boosting: Implementing different ensemble techniques like bagging and boosting to improve the predictive ability of the model\n\nHow to build this machine learning project:\n\n    Collect the medical insurance dataset by web scraping with Python libraries like BeautifulSoup or requests \n    Clean the data, handle missing values, encode categorical variables, and preprocess the data for training your model\n    Determine the relationship between features and target variables using visualization techniques like scatter plots, histograms, etc.\n    Split the data into training and testing datasets and try using different supervised learning algorithms like linear regression, decision trees, etc.\n    Evaluate the performance of the model considering multiple metrics like R-squared, mean squared error, and root mean squared error\n    Implement ensemble methods like bagging and boosting, including AdaBoost and Gradient Boosting, to improve the predictive ability of the model \n    Evaluate the overall performance of the model based on the test dataset and ensure it is ready for use \n\nReal world applications: \n\n    Individuals can use the tool for family or single insurance planning and estimate the cost based on multiple factors like age, chronic health conditions, etc \n    Healthcare providers can implement the tool to understand what factors influence insurance costs and optimize their pricing strategies and patient care plans\n    Government can leverage this model to predict insurance costs to develop effective healthcare policies and ensure fair and affordable healthcare and medical insurance access to all \n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2022",
    "tech_stack": "Python, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, BeautifulSoup",
    "objective": [
      "Build a machine learning model to predict medical insurance prices based on various factors.",
      "Optimize the model for better performance using ensemble techniques like bagging and boosting."
    ],
    "source": "ISE-dept"
  },
  {
    "project_id": "auto009",
    "title": "Credit card clustering",
    "description": "This project aims to create a cluster of customers with similar credit card spending patterns, providing valuable insights for credit card companies. It will use Python libraries and unsupervised machine-learning techniques to analyze credit card transaction data and identify customer segments.\n\nLearning outcomes: \n\n    Basic understanding of machine learning and Python: Get handsome experience with Python libraries in machine learning projects and knowledge of basic ML concepts\n    Exploratory data analysis using Python library: Learn the use of two popular Python libraries, Pandas and NumPy, and their use in data manipulation and analysis and scientific computing\n    Data engineering and preprocessing: Understand how to prepare your data for analysis, handle missing values, scale features, data cleaning, and dealing with categorical variables \n    Unsupervised learning technique: Learn the use of clustering models in unsupervised learning techniques to group customers based on their spending behavior\n    Model evaluation: Knowledge of evaluating a modelâ€™s performance using different evaluation metrics and techniques like the Elbow method and Silhouette Analysis \n    Data visualization: Use of multiple Python libraries like Matplotlib, Seaborn, and Plotly for data visualization and interpretation\n\nHow to build this machine learning project:\n\n    Gather a dataset of credit card transactions with a web scraping tool \n    Clean the data, handle missing values, and scale features to prepare the data for analysis \n    Analyze the data, identify features, and visualize data for a better understanding of hidden patterns \n    Apply clustering algorithms like K-means Clustering and DBSCAN to group customers based on their spending behavior\n    Evaluate the performance of the clustering model and optimize it for better results\n\nReal world applications: \n\n    Credit card companies can use the tool to identify distinct customer segments having similar spending patterns that help them provide personalized offers, targeted marketing campaigns, and customer retention strategies\n    Fraud detection agencies can use it to detect anomalous spending behavior, which can be an indicator of fraudulent transactions\n    Banks and financial institutions can use it to understand the spending habits of their customer segment and offer tailored rewards programs, financial planning advice, and  credit card adjustments\n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2023",
    "tech_stack": "Python, Flask, Pandas, NumPy, Matplotlib, Seaborn, Plotly, Scikit-learn, Scipy, SQL",
    "objective": "Build a clustering model to identify customer segments based on their credit card spending patterns.",
    "source": "ISE-dept"
  },
  {
    "project_id": "auto010",
    "title": "MNIST Data",
    "description": "The aim of this project is to work with the MNIST dataset that contains handwritten digit images to understand its underlying data structure.\n\nLearning outcomes: \n\n    Basic understanding of machine learning techniques and Python: Learn how machine Learning works and use different Python libraries in deploying machine learning projects\n    Data preprocessing: Knowledge of how to load and preprocess the MNIST dataset along with normalizing the pixel values and reshaping the data \n    Dimensionality reduction unsupervised learning algorithm: Understanding of applying dimensionality reduction algorithms like PCA and t-SNE on the MNIST data \n    Data visualization: Learning how to create visualizations like scatter plots and t-SNE embeddings to understand the structure of the MNIST data\n    Model evaluation: How to evaluate the performance of your model using multiple evaluation metrics \n\nHow to build this machine learning project:\n\n    Install required Python libraries like NumPy, Scikit-learn, Pandas, Matplotlib, Seaborn, and Plotly for the project \n    Collect MNIST data by web scraping and then preprocess the data by normalizing the pixel values and reshaping the images\n    Implement dimensionality reduction techniques like PCA using the Scikit-learn library \n    Build a simple classifier using a logistic regression model or a neural network  and evaluate its performance \n\nReal world applications: \n\n    MNIST data can be used in developing handwritten character recognition systems required in document processing and bank check processing \n    It can be implemented in the signature verification process to ensure security and authentication \n    MNIST dataset serves as the starting point for developing image analysis and classification techniques \n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2021",
    "tech_stack": "Python, NumPy, Scikit-learn, Pandas, Matplotlib, Seaborn, Plotly",
    "objective": "Build a machine learning project using MNIST dataset to recognize handwritten digits and evaluate its performance",
    "source": "ISE-dept"
  },
  {
    "project_id": "auto011",
    "title": "Real time sentiment analysis",
    "description": "A sentiment analysis system will determine the emotional tone behind a text, whether it is positive, negative, or neutral, in real time. \n\nLearning outcomes: \n\n    Basic understanding of machine learning and Python libraries: Knowledge of implementing multiple Python libraries in completing the project and having a good understanding of machine learning concepts\n    Data manipulation: Use of Python library Pandas to load, clean, and preprocess the text data for training machines \n    Natural language processing: Applying different National language processing techniques like tokenization, stemming, and lemmatization\n    Sentiment analysis: Use of different sentiment analysis techniques, building a model with supervised learning, and evaluating its performance \n\nHow to build this machine learning project:\n\n    Install required Python libraries for the project like Scikit-learn, Pandas, Matplotlib, NumPy \n    Data collection with known sentiment labels by web scraping techniques\n    Clean and preprocess the text data using Python libraries like Pandas, remove stopwords and stemming or lemmatizing words, and convert text to numerical format for machine learning \n    Split the pre-process data into training and testing datasets and train your machine model with appropriate algorithms like SVM, KNN, and Naive Bayes to classify the sentiment of the text \n    Evaluate the performance of the trained model with appropriate model evaluation metrics like accuracy, precision, recall, and F1-score\n    Integrate the trained model into the real-time application to accept user input and output the predicted sentiment using Python web frameworks like Flask and Django \n\nReal world applications: \n\n    Customer service centers can use it to analyze customer feedback and support conversations, quickly identify and address any negative sentiments, and improve customer satisfaction \n    Social media marketers can use it to track the sentiment of online conversations about a product, a brand, or an event for improved marketing and public relations strategies\n    Financial analysts can use it to monitor news and social media platforms for determining market sentiment and making informed investment decisions\n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2024",
    "tech_stack": "Python 3.x, Flask, Scikit-learn, Pandas, Matplotlib, NumPy",
    "objective": "Build a real-time sentiment analysis system that determines emotional tone behind text and classifies sentiment as positive, negative, or neutral using machine learning algorithms.",
    "source": "ISE-dept"
  },
  {
    "project_id": "auto012",
    "title": "News recommendation system",
    "description": "This project aims at defining user preferences and analyzing multiple news articles to provide personalized news recommendations to individual users. \n\nLearning outcomes: \n\n    Web scraping: Learn how to extract news articles from different websites using Python library like BeautifulSoup \n    Data preprocessing: Knowledge of cleaning and transforming text data for training machine learning models \n    Recommendation algorithms: Understanding the concept of recommendation systems and their types mainly collaborative filtering and content-based filtering\n    Machine learning model training and evaluation: Knowledge of how to train recommendation models and assess their performance using multiple evaluation metrics \n    User interface development: Hands-on training on building a web-based interface to showcase your news recommendation system\n\nHow to build this machine learning project:\n\n    Set up the development environment by installing Python along with its necessary libraries and any web framework like Flask or Django \n    Use web scraping techniques to collect news data from various websites and online sources \n    Preprocess the data, clean the news text, extract relevant features, and encode the data for training recommendation models\n    Implement a recommendation system including content-based filtering, collaborative filtering, or a hybrid model to generate personalized news  recommendations\n    Split the data into training and testing sets, train the recommendation model, and evaluate its performance using different metrics like precision, recall, and F1-score \n    Create a web-based application that allows users to interact with the news recommendation system, view recommended news articles, and provide feedback\n\nReal world applications: \n\n    News organizations can use this system to offer personalized news recommendations to their readers and improve user engagement \n    Social media platforms can use it to leverage news recommendations to users, keeping them informed and engaged with any brand or content creators \n    Companies can use this news recommendation system to keep their employees updated with industry news and trends and improve their knowledge and decision-making process\n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2020",
    "tech_stack": "Flask, BeautifulSoup, Pandas, NumPy, Scikit-learn, TensorFlow, Python",
    "objective": [
      "Develop a personalized news recommendation system using web scraping, content-based filtering, and collaborative filtering",
      "Train a machine learning model to recommend news articles to individual users based on their preferences"
    ],
    "source": "ISE-dept"
  },
  {
    "project_id": "auto013",
    "title": "Calories Burnt Prediction",
    "description": "The Calories Burnt Prediction project aims to develop a model that can predict the number of calories a person can burn depending on various factors. \n\nLearning outcomes: \n\n    Python programming: Learn Python programming basic concepts, including working with data structures, file handling, and data  manipulation, and the use of Python libraries \n    Data preprocessing: Understand different techniques for cleaning, handling missing values, and transforming data into formats appropriate to train machines\n    Feature engineering: Knowledge of how to create new features from existing data and improve your training model performance \n    Machine learning algorithms: Knowledge of applying different algorithms like linear regression, decision trees, and random forests to solve a real-world problem \n    Model evaluation: Evaluate the performance of the train model using multiple metrics like Mean Squared Error, R-squared, etc.\n\nHow to build this machine learning project:\n\n    Installing Python and the required library for the project \n    Gather data from online sources with web scraping techniques \n    Clean the dataset by handling missing values, converting data types, and normalizing the features\n    Analyze the data and create new features from it that can improve the modelâ€™s performance, such as body mass index or activity intensity \n    Split the data into training and testing datasets and use it to train your chosen model\n    Evaluate the performance of your model using appropriate metrics \n    Optimize the modelâ€™s hyperparameters to improve its performance \n    Integrate the model with a simple web application to allow users to provide input and receive predictions on the number of calories burned\n\nReal world applications: \n\n    Fitness companies can use this model with their fitness tracking apps or wearable devices to provide users with accurate calorie burn estimates during workout or daily activities\n    Individuals can use the system to better understand their calorie loss and have effective weight management plans \n    Athletes and coaches can use the system to optimize their training process and monitor the calories burnt during different types of exercises\n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2020",
    "tech_stack": "Python, Flask, Scikit-Learn, Pandas",
    "objective": [
      "Develop a machine learning model to predict calories burnt based on various factors",
      "Integrate the model with a web application for user input and prediction",
      "Provide accurate calorie burn estimates for fitness companies, individuals, athletes, and coaches"
    ],
    "source": "ISE-dept"
  },
  {
    "project_id": "auto014",
    "title": "Online Payment Fraud Detection",
    "description": "This online payment fraud detection project aims to help students learn how to build a system that can identify fraudulent online transactions.  The model will work with a dataset of previous online transactions and train machine learning models to recognize patterns that distinguish fraud activities from normal transactions.\n\nLearning outcomes: \n\n    Basic knowledge of Python libraries: Use of different Python libraries like Pandas, NumPy, matplotlib, etc., for performing multiple tasks within machine learning projects \n    Web scraping: Learn how to extract data from different web pages using scraping techniques \n    Data handling techniques: Knowledge of how to preprocess the data before feeding them to a machine learning model using Python libraries like Pandas and NumPy \n    Feature engineering: Understanding of data cleaning and handling missing values, creating new features from existing data, and encoding categorical variables\n    Model selection and evaluation: Learn how to split the data into training and testing sets, use appropriate ML algorithms, and evaluate the modelâ€™s performance using different metrics\n\nHow to build this machine learning project:\n\n    Install Python and its required libraries for developing the machine learning project \n    Gather data from different online transactions, learn its features, and preprocess the data for feeding machine learning models \n    Analyze the data and create new features that can improve your modelâ€™s ability to detect fraud transactions \n    Choose an appropriate machine learning algorithm like logistic regression or decision trees and train the model on the prepared data \n    Split the data into training and testing sets, evaluate the modelâ€™s performance using relevant evaluation metrics, and fine-tune the model \n    Integrate the trained model into a real-world application like a mobile payment app or e-commerce platform to detect and prevent online payment fraud\n\nReal world applications: \n\n    Online retailers can integrate this model into their payment processing systems to identify potentially fraudulent transactions\n    Integrate this tool with different Mobile payment apps to detect fraud in online transactions \n    Banks and credit card companies can use this system to monitor their customer transactions and identify suspicious activities in real-time\n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2023",
    "tech_stack": "Python 3.8+, Pandas, NumPy, matplotlib, Scikit-learn, Flask",
    "objective": "Build a machine learning model to detect online payment fraud using data preprocessing and feature engineering techniques.",
    "source": "ISE-dept"
  },
  {
    "project_id": "auto015",
    "title": "Rainfall Prediction system",
    "description": "This project aims to develop a model capable of predicting rainfall patterns in the future based on past meteorological data. Learners will get hands-on practice collecting and preprocessing meteorological data, using different machine learning algorithms, and training a model to make accurate rainfall predictions.\n\nLearning outcomes: \n\n    Data collection: Learn how to collect existing rainfall data along with other essential features like temperature, humidity, and atmospheric pressure from reliable web sources\n    Data preprocessing: Knowledge of how to clean and preprocess the data, handle missing values, outliers, or inconsistencies, and ensure the data is suitable for training models\n    Exploratory Data Analysis: Familiarity with data visualization techniques using Python libraries like Matplotlib and Seaborn to gain valuable insights from the data\n    Feature engineering: Understanding of feature selection and creation to improve the predictive ability of the model\n    Use of Machine Learning algorithms: Knowledge of different machine learning algorithms and evaluate their performance \n\nHow to build this machine learning project:\n\n    Setup the development environment with Python and its necessary libraries\n    Collect rainfall data and other relevant meteorological features from reliable sources with web scraping techniques \n    Preprocess the data before feeding it to the machine-learning model\n    Train the machine learning model with appropriate algorithms for predicting rainfall \n    Assess the modelâ€™s performance using appropriate evaluation metrics and finetune the hyperparameters to improve prediction accuracy\n    Integrate the model into a larger system or create a web application\n\nReal world applications: \n\n    Farmers can use this tool to predict rainfall and plan their crop management activities \n    Local authorities in water management agencies can use it to forecast water availability and implement different water conservation strategies \n    Disaster management authorities can use it to understand rainfall rates and provide early warnings to prepare people for a disaster \n\nðŸ‘‰ Find the source code",
    "domain": "Artificial Intelligence / Data Science",
    "year": "2024",
    "tech_stack": "Python, Flask (fallback)",
    "objective": "Automatic generation failed; placeholder added.",
    "source": "ISE-dept"
  }
]